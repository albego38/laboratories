{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **BRONZE TO SILVER ENGINE**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Parámetros**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre de la tabla destino\r\n",
        "table_name = \"h_transactions\"\r\n",
        "# Nombre de la cuenta de almacenamiento ADLS Gen2. Ej: dlsmde01albego\r\n",
        "storage_account_name = \"SUSTITUIR\""
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Proceso**\r\n",
        "\r\n",
        "01. Definición de variables y rutas de acceso."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from delta.tables import DeltaTable\r\n",
        "from pyspark.sql.functions import current_date\r\n",
        "\r\n",
        "# Definir variables\r\n",
        "data_lake_container = f'abfss://datalake@{storage_account_name}.dfs.core.windows.net'\r\n",
        "bronze_folder = 'bronze'    # Carpeta de ingesta de datos (raw)\r\n",
        "silver_folder = 'silver'    # Carpeta donde se almacenarán las tablas Delta\r\n",
        "\r\n",
        "# Determinar la ruta de los archivos de origen\r\n",
        "source_path = f\"{data_lake_container}/{bronze_folder}/\"\r\n",
        "\r\n",
        "# Determinar la ruta de la tabla Delta\r\n",
        "delta_table_path = f\"{data_lake_container}/{silver_folder}/{table_name}\""
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Lectura de archivos de la capa bronze y creación de nuevo campo de fecha de carga del dato (load_date)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer archivo(s) en DataFrame de Spark\r\n",
        "sdf = spark.read.format('csv').option(\"sep\", \",\").option(\"encoding\", \"ISO-8859-1\").option(\"header\", \"true\").load(source_path)\r\n",
        "\r\n",
        "# Añadir una columna con la fecha de carga \r\n",
        "sdf = sdf.withColumn(\"load_date\", current_date())\r\n",
        "\r\n",
        "sdf.show(10)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Creación del fichero en Delta en ADLS Gen2 capa silver."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear nueva tabla Delta con los datos nuevos\r\n",
        "print('Creating new Delta table...')\r\n",
        "sdf.write.format('delta').mode(\"overwrite\").save(delta_table_path)\r\n",
        "\r\n",
        "# Leer la tabla Delta y mostrar su contenido\r\n",
        "delta_df = spark.read.format(\"delta\").load(delta_table_path)\r\n",
        "print('Showing content of the Delta table...')\r\n",
        "delta_df.show(10)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Creación de la base de datos silver y una tabla externa delta utilizando la localización del fichero del punto anterior. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear base de datos Silver si no existe\r\n",
        "spark.sql('CREATE DATABASE IF NOT EXISTS Silver')\r\n",
        "\r\n",
        "# Añadir la tabla Delta a la base de datos Silver para facilitar consultas\r\n",
        "spark.sql(f'CREATE TABLE IF NOT EXISTS Silver.{table_name} USING DELTA LOCATION \\'{delta_table_path}\\'')\r\n",
        "\r\n",
        "# Consultar el recuento de filas en la tabla\r\n",
        "count_df = spark.sql(f'SELECT COUNT(*) FROM Silver.{table_name}')"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Consultar la información del resultado."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar el recuento en pantalla\r\n",
        "print('Showing row count...')\r\n",
        "count_df.show()\r\n",
        "\r\n",
        "# Consultar y mostrar los primeros 10 registros de la tabla\r\n",
        "df = spark.sql(f'SELECT * FROM Silver.{table_name}')\r\n",
        "print('Showing first 10 records...')\r\n",
        "df.show(10, truncate=False)"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mssparkutils.session.stop()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": false,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}